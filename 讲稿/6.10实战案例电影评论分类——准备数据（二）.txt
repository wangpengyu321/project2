文件：6.10神经网络实战案例：电影评论分类——准备数据（二）
P1：同学们大家好，上节课我们给大家讲到由字典所生成的所有列表的数据都需要转换为固定维度的编码形式，才能将数据集以统一的维度送入神经网络进行训练。那么，如何实现这种转换呢？这就是本节课我们将继续探讨的内容。
P2：所采用的方法也就是将之前的列表转换为张量。这里，我们给大家介绍一种称之为独热码的方法，即One-hot编码方法。所谓One-hot编码，又称为一位有效编码，是分类变量作为二进制向量的一种表示方法。也就是对列表进行one-hot编码，就是将其转换为0和1所组成的一个向量。举一个例子，比如说，有一个评论只有2个词，假设其索引所组成的序列是[3,5]，通过One-hot编码，将会将其转换为一个10000维的向量。这里，大家思考一下，为什么会被转换为一个10000维向量？因为我们在之前准备数据的时候，是不是在字典里选取的就是前10000个高频的单词啊。也就是这10000个词都有可能会在你的评论里出现，所以我们就选10000维的向量，而One-hot编码时，序列的列表里有3，那就在10000维向量中的索引为3的这个位置，其元素值设置为1；序列的列表里有5，那就在10000维向量中的索引为5的这个位置，其元素值设置为1；而其余所有索引位置的元素都设置为0。这就是独热码的编码方法。这种方法的好处，就是将所有的评论都格式化为了一个统一维度的固定长度的形式。
P3：好，下面我们通过一个小练习来进一步强化一下对One-hot编码的理解。我们给大家提供这样一个字典。这里出于简化，我们不选择之前的10000个的字典，而是选择只有5个键值对所组成的，///其具体是这样一种形式，dislike对应的值为0，like对应1，I对应的2， movie对应的3，this对应的4。///假如，某条评论是“I like this movie”，大家来看一下，其///向量化后的数据是什么呢？是不是就是[2,1,4,3]啊，为什么呢？是不是就是查字典查出来的啊。因为，字典的键值对中，I对应的是2，like对应的是1，this对应的是4，movie对应的是3，所以向量化后的数据就是[2,1,4,3]。那么，///进一步将其转换为One-hot编码，是什么呢，这里假设格式化的One-hot编码，每条评论对应的都是5维的长度。那么，[2,1,4,3]转换后的One-hot编码就是/// [0,1,1,1,1]。为什么？我们来看，根据One-hot编码的方法，索引为2的位置，其元素值设置为1，索引为1的位置，其元素值设置为1，索引为4的位置，其元素值设置为1，索引为3的位置，其元素值设置为1，因为没有出现索引0，即没有出现dislike这个单词，所以One-hot编码中的索引0的位置，其元素值就是0。所以，转化后的One-hot编码就是[0,1,1,1,1]。
P4：好了，介绍了以上的字典的方法以及One-hot独热码的方法，我们再进一步看，比如，训练数据train_data[0]，也就是第1条评论，通过字典键值对的转换，形成了一个列表，这个列表的维度不确定，因为其维度是由评论的长度所定的，然后再通过独热码的转换，比如，这个值有1，那么下面索引1的位置就为1，这有值14,22,66，那么下面索引为14,22,66的位置的元素值也都为1，以此类推。这样，就转换成x_train[0]，这样的独热码的0、1编码的向量形式，这个向量的维度就是10000维。
P5：然后，就是样本标签的张量化，这里，就不再多说了，因为本身这里的标签就是张量形式的，这里只是将其转换为高精度的之而已。
好了，同学们，通过上面的方法一旦得到了固定维度的数据，就可以将其送入神经网络进行学习了，以上就是我们关于电影评论分类之准备数据的相关内容，今天的课就介绍到这里，谢谢大家。