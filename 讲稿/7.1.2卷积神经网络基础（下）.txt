P2，本节课我们继续讲全连接网络存在的问题，和解决问题的方法。上次我们讲到使用物体的局部特征来识别物体。为什么使用物体局部的图像可以识别物体呢？这里我们先讲一下图像数据的局部相关性，也就是基于距离的重要性分布假设特性。在人们看到物体时候，只关注与自己距离较近的部分节点，而忽略距离较远的节点，这些较近的局部特征，就已经可以使人，认出这个物体，那么计算机在运用神经网络识别物体时候，也运用了这样的原理，就是感受野。
P16，什么是感受野？以眼睛看到房间的猫，并认出猫的过程为例。当眼睛看到猫，眼睛器官受刺激兴奋，通过眼睛这个感受器官中的向心神经元，将神经冲动，也就是看到猫的这个视觉信息，传到上位中枢，这个冲动的神经元所反应的刺激区域，就叫神经元感受野。卷积神经网络是受生物学上感受野机制启发而提出的。以这个图为例，人识别出来，这是只猫，跟房间中，猫之外的图像信息没关系，甚至我们只看到猫的头部，或者猫的尾巴和躯干等一部分猫的身体信息，我们就能认出来，这是只猫。也就是识别出来猫，只需要图像的局部区域。
P17，基于感受野的机制，图像识别的网络模型，就发展成，找到一个参考点，然后构建一个以他为中心，边长为k的正方形网格，作为整个图像的局部区域，也就是感受野。然后计算该感受野内，每个像素对于中心像素的重要性分布情况，或者说计算感受野内图像的特征，并进行特征传递。此时，该网格内的像素的特征才被传递，网格外的像素对于中心像素特征会被直接忽略掉。
P18，权值共享，也就是我们用k×k规模的参数，来代替该层的一个神经元，下面称为节点，与每一个输入节点之间全连接的大规模参数，该层每个节点仅与感受野区域内，k×k个输入节点相连接，是与该层连接的输入层参数多少无关的。当输出层节点为L，则当前层的参数量为k×k×L+L，这里的k取值一般比较小，加的L，是指该节点后面的偏差参数b。因此权值共享，成功地将参数量减少了很多。以图中的玩具熊识别为例，在网络模型的某个输出节点，使用一个W为3*3大小的感受野区域，来与输入的图像计算，进行特征的传递。该节点计算时参数有9个感受野参数和1个偏差参数，也就是将这10个参数与输入计算出来的图像特征，传递到下一层，当然这9+1个参数是需要通过前面讲的误差反向传播算法，也就是BP算法，不断进行优化，得到最佳参数值。
P19，为了减少参数，在卷积神经网络中，还加入了特征映射池化层，也就是如图所示，通过一定规则，减少参数量。如图，是使用最大池化法，将一个4*4的特征矩阵，减小为2*2的特征矩阵，这样与其相连接的参数就大幅减少，而且实验研究发现，这样简单粗暴的减少参数，不仅识别准确率没有降低，在很一定程度上，也解决了过拟合的问题。关于池化的计算方法，我们将在后面知识点讲解。
P20，我们对讲的知识点做一个总结。我们前面围绕为什么用卷积神经网络讲了几个问题。首先，我们讲了卷积神经网络取得的成绩，然后指出全连接神经网络的缺点，也就是第一，全连接网络参数多，第二，全连接网络对具有局部不变性特征的物体识别率低。为解决这两个问题，提出来了具有局部连接，权值共享，池化，三个特点的卷积神经网络，我们已经简单对卷积神经网络有了认识，下次课，我们讲什么是卷积？这节课就讲到这里，同学们再见。

