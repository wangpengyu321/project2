文件：6.3神经网络搭建流程——选择评估指标、确定评估方法
P1、2：同学们大家好，本节课，我们针对神经网络搭建的流程，继续学习选择评估指标、确定评估方法这一部分内容。
P3：好，上一节我们给大家介绍了“收集数据集、准备数据”这一流程步骤，那么准备好了数据之后，我们需要干什么呢？就是评估指标的选择。也就是你这个模型要选择什么样的评估指标。我们在之前章节里学习过，评估指标主要有，准确率、精准率、召回率和F指数。那我们选择什么评估指标呢，我们可以将所探讨的问题分为两大类，///首先，就是第一种，平衡分类问题，比如说我们之前所介绍过的MNIST手写数字分类。通过这个名称，我们就能感受到，什么平衡分类，也就是0-9的10个类别，没有很明显的倾向性，比如是倾向于找数字1，还是倾向于找数字2这样的倾向性问题，都不是的，而给通过所给的一个数字，能够判断出该数字的类别，这就是平衡分类问题。这在数据集上体现的是每一类所包含的样本数基本上都是均衡的，比如MNIST的6万张数据集图片，它的0-9每一类数据都是6千张，总共形成了6万张的图片。那么对于平衡分类问题，我们主要关注它的哪个指标呢？就是准确率。所谓准确率，我们之前讲过，就是分类正确的样本数占所有样本数量的比例，在MNIST中就是，0判断为了0，1判断为了1，2判断为了2，一直到9判断为了9，都判断正确了，就是分类正确的样本数，而这也就是我们平衡分类问题中的准确率。///那么，在非平衡分类的问题中，我们关注的又是什么呢，一个典型的例子就是寻找新冠感染者。为什么称之为非平衡分类问题呢，大家可以想一下，对于这个例子而言，感染新冠的人和正常的人，比例一样吗？很明显，不一样。那么这个时候，通过设计一个算法，寻找新冠感染的人，还能用准确率这一评估指标吗？比如说，假如有10000个人进行新冠检测，而这10000人中有1人是新冠感染者，其余的9999人都是正常人，而在新冠预测中，只有这1人预测错了，被划分到了正常人的类别中，其余的9999人都预测对了，都属于正常人的类别，那么，这个问题的预测准确率也就是高达9999/10000，接近于100%的。从这里可以看出，高达接近100%的准确率在这个问题中是没有什么意思，因为我们是想精确的找到那1个新冠感染者，但却没有预测出来。所以说，在非平衡分类问题中，使用准确率，就失去了其评估的作用了。///因此，这个时候，我们就需要用到精确率和召回率这两个评估指标了。精确率就是，10000人中，识别到2人为新冠感染者，实际上其中有1人确实是，那么精确率就是1/2，50%，如果这两人实际上都是新冠感染者的话，那么精确率就是100%；而召回率则是指，10000人，有1人是新冠感染者，预测时也将他准确的识别出来的，那么召回率就是100%，如果有10000人中有2人是新冠感染者，预测时只将其中的1人确认识别了出来，那么召回率就是50%。所以说，与准确率相比，非平衡问题更适合于使用精确率和召回率这两个评估指标。
P4：选择了评估指标，我们还要选择合适的评估方法。评估方法就是如何用于评估我们的训练效果。我们常见的三种评估方法以及对应的使用场景就是，///第一，留出验证集，也就是从训练集中留出一部分数据，作为验证集来使用。这种情况适用于数据量比较大的时候。比如说有1000万人的数据，来预测人的胖瘦，这1000万的数据量很大，数据量一旦很大，就具有了一定的代表意义。这个时候，就可以留出200万人的数据来做为验证集，而这200万人就可以代表了1000万人中的数据分布特征。///但假如说，我们要预测咱们班级里总共50个同学的成绩，我还按留出验证集的方法挑出其中的10个人，想要作为验证集使用的话，因为这个数据集很小，而又刚好挑的是班里的前10名，那么这10名的成绩就不能代表50人的成绩情况，因而，这种方法，会因为训练集和验证集之间的分配不均衡而使得模型存在较大的偏差。那怎么办呢，这时，///我们就采用第二种方法，K折交叉验证，我们将50个人，分为10个人、10个人的一组，总共做5次实验，每次都使用这不同的10人作为验证集，其余40人作为训练集，5次的实验再去平均值，这样就能够消除成绩分布不均衡的情况，这就是K折交叉验证的方法，较为适用于数据量比较小的时候。///另外，就是重复的K折验证，就是在数据量很少，模型评估又需要非常准确的情况下，我们就使用重复的K折交叉验证，就是在上述K折交叉验证的基础上，我们再重复使用几次。这就是我们所说的常见的评估方法及其对应的使用场景。
好了，同学们，以上就是我们这节课所讲的关于神经网络搭建的流程之选择评估指标、确定评估方法的相关内容，今天的课就介绍到这里，谢谢大家。



注1：
