P2 同学好，本讲向大家介绍神经网络的数据预处理与特征工程。
除模型评估之外，在深入研究模型开发之前，我们还必须解决另一个重要问题：将数据输入神经网络之前，如何准备输入数据和目标？许多数据预处理方法和特征工程技术都是和特定领域相关的，本讲我们要介绍预处理的基本思路与通用方法。数据预处理的目的是使原始数据更适于用神经网络处理，包括向量化、标准化、处理缺失值和特征提取。 \\\首先是“向量化”，神经网络的所有输入和目标除了在特定情况下可以是整数张量，一般都是浮点数张量。无论处理什么数据，例如声音、图像还是文本，都必须首先将其转换为张量，这一步叫作数据向量化。\\\其次是“值标准化”。一般来说，取值相对较大的数据，比如比网络权重的初始值大很多的整数，或异质数据，即数据的一个特征在 0~1 范围内，另一个特征在 100~200 范围内，将这些数据输入到神经网络中是不安全的。这么做可能导致较大的梯度更新，进而导致网络无法收敛。为了让网络的学习变得更容易，输入数据应该具有以下特征：取值较小：大部分值都应该在0~1范围内；同质性，所有特征的取值都应该在大致相同的范围内。比较严格的做法是将数据输入网络之前，需要对每个特征分别做标准化，使其均值为0、标准差为1。在手写数字分类的例子中，开始时图像数据被编码为 0~255 范围内的整数，表示灰度值。将这一数据输入网络之前，你需要将其转换为 float32 格式并除以 255，这样就得到 0~1 范围内的浮点数；\\\再者是“处理缺失值”，你的数据中有时可能会有缺失值。一般来说，对于神经网络，将缺失值设置为0是安全的，只要0不是一个有意义的值。网络能够从数据中学到 0 意味着缺失数据，并且会忽略这个值。
P3 特征工程指将数据输入模型之前，利用关于数据和神经网络的知识对数据进行硬编码的变换（不是模型学到的），以改善模型的效果。
P4 我们来看一个直观的例子。假设你想开发一个模型，输入一个时钟图像，模型能够输出对应的时间，如果你选择用图像的原始像素作为输入数据，那么这个机器学习问题将非常困难。但如果你从更高的层次理解了这个问题（你知道人们怎么看时钟上的时间），那么可以为机器学习算法找到更好的输入特征，\\\比如找到时钟指针对应的黑色像素并输出每个指针尖的 (x, y) 坐标，这样每个样本的特征就只包括4个特征数据，一个简单的机器学习算法就可以学会这些坐标与时间的对应关系。\\\有没有更加简洁的特征表示方法呢？比如进行坐标变换，将 (x, y) 坐标转换为相对于图像中心的极坐标。这样输入就变成了每个时钟指针的角度 theta。这就是特征工程的本质：用更简单的方式表述问题，从而使问题变得更容易。它通常需要深入理解问题。
P5 深度学习出现之前，特征工程曾经非常重要，因为经典的浅层算法没有足够大的假设空间来自己学习有用的表示。将数据呈现给算法的方式对解决问题至关重要。例如，卷积神经网络在 MNIST 数字分类问题上取得成功之前，其解决方法通常是基于硬编码的特征，比如数字图像中的圆圈个数、图像中每个数字的高度、像素值的直方图等。
幸运的是，对于现代深度学习，大部分特征工程都是不需要的，因为神经网络能够从原始数据中自动提取有用的特征。这是否意味着，只要使用深度神经网络，就无须担心特征工程呢？并不是这样，原因有两点。\\\第一、选取合适的特征仍然可以用更少的资源更优雅地解决问题。\\\第二，选取合适特征可以让你用更少的数据解决问题。深度学习模型自主学习特征的能力依赖于大量的训练数据。如果只有很少的样本，那么特征的信息价值就变得非常重要。
本讲内容就到这里，谢谢。