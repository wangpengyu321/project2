知识点1：人工智能的定义
P2  人工智能与机器学习
P3  1956年8月，在美国汉诺斯小镇宁静的达特茅斯学院中，众多各学科领域的专家齐聚一堂，包括数学家约翰·麦卡锡、人工智能与认知学专家马文·闵斯基、信息论的创始人克劳德·香农、计算机科学家艾伦·纽厄尔、诺贝尔经济学奖得主赫伯特·西蒙等科学家正聚在一起，讨论着一个完全不食人间烟火的主题：用机器来模仿人类学习以及其他方面的智能。用通俗的语言说就是”计算机是否能够思考？”
P4 人工智能的简洁定义如下：努力将通常由人类完成的智力任务自动化。 1980 年代以前，科学家们尝试通过知识库加推理的方式解决人工智能，通过构建庞大复杂的专家系统来模拟人类专家的智能水平。在相当长的时间内，许多专家相信，只要程序员精心编写足够多的明确规则来处理知识，就可以实现与人类水平相当的人工智能。象棋程序就是一个典型的专家系统，通过向计算机输入大量的棋谱，即知识库，同时利用程序告知计算机走棋的规则，就能够实现象棋专家系统与人类的博弈。但你应该感受到，这些明确指定规则的方式存在一个最大的难题，就是很多复杂、 抽象的概念无法用具体的代码实现。比如人类对图片的识别、 对语言的理解过程，是根本无法通过既定规则模拟。
   为了解决这类问题，一门通过让机器自动从数据中学习规则的研究学科诞生了，称为机器学习，并在 1980 年代成为人工智能中的热门学科。 
P5 验证码（CAPTCHA）是“Completely Automated Public Turing test to tell Computers and Humans Apart”（全自动区分计算机和人类的图灵测试）的缩写，是一种区分用户是计算机还是人的公共全自动程序。可以防止：恶意破解密码、刷票、论坛灌水，有效防止某个黑客对某一个特定注册用户用特定程序暴力破解方式进行不断的登陆尝试。
在登录某网站、App、注册、提交表单时，绝大多数情况下，都会有验证码的功能。用户只有在验证码输入正确的情况下才可进行接下来的操作。
图灵测试：将人与机器隔开，前者通过一些装置（如键盘）向后者随意提问。多次问答后，如果有超过30%的人不能确定出被测试者是人还是机器，那么这台机器就通过了测试，并被认为具有人类智能。
知识点2：机器学习
P6 说起机器学习，不得不提的一个任务就是人工智能先驱阿兰 • 图灵，我们都知道诺贝尔奖是全世界范围内最高的科学奖项，但大家也应该知道诺贝尔奖项中是没有计算机领域的奖项的，而以阿兰 • 图灵名字命名的图灵奖就是被称为计算机领域中的诺贝尔奖的最高奖项。
人们如此尊崇阿兰图灵，不仅因为他在二战中破解德军的密码中做出的巨大贡献，更因为他在计算机发展中做出的杰出工作。在其 1950 年发表的具有里程碑意义的论文“计算机器和智能”中介绍了图灵测试以及日后人工智能所包含的重要概念。图灵还思考了这样一个问题：通用计算机是否能够学习与创新？机器学习的概念就来自于图灵的这个问题：对于计算机而言，除了“我们命令它做的任何事情”之外，它能否自我学习执行特定任务的方法？计算机能否让我们大吃一惊？如果没有程序员精心编写的数据处理规则，计算机能否通过观察数据自动学会这些规则？图灵得出的结论是“能”。
P7 图灵的这个问题引出了一种新的编程范式。在经典的程序设计（即符号主义人工智能的范式）中，人们输入的是规则（即程序）和需要根据这些规则进行处理的数据，系统输出的是答案（单击）。利用机器学习，人们输入的是数据和从这些数据中预期得到的答案，系统输出的是规则。这些规则随后可应用于新的数据，并使计算机自主生成答案。 
机器学习系统是训练出来的，而不是明确地用程序编写出来的。将与某个任务相关的许多示例输入机器学习系统，它会在这些示例中找到统计结构，从而最终找到规则将任务自动化。
举个例子，你想为度假照片添加标签，并且希望将这项任务自动化，那么你可以将许多人工打好标签的照片输入机器学习系统，系统将学会将照片与特定标签联系在一起的统计规则。
P8 20世纪90年代，机器学习开始蓬勃发展，源于速度更快的硬件和更大的数据集。机器学习的三个要素：输入数据、数据对应的标签、衡量算法的方法。衡量算法的方法生成的是一种反馈信号，用于调节算法的工作方式，调节步骤称之为“学习” .
P9 机器学习模型将输入数据变换为有意义的输出，这是一个从已知的输入和输出示例中进行“学习”的过程 ，所以机器学习的核心问题：有意义地变换数据。
学习输入数据的有用表示。什么是表示？以一种不同的方式来查看数据（即表征数据或将数据编码） 例如，彩色图像可以编码为 RGB（红 - 绿 - 蓝） 格式或 HSV（色相 - 饱和度 - 明度）格式，这是对相同数据的两种不同表示。 对于“选择图像中所有红色像素”这个任务，使用 RGB 格式会更简单，而对于“降低图像饱和度”这个任务，使用 HSV 格式则更简单。机器学习模型都是为输入数据寻找合适的表示——对数据进行变换，使其更适合手头的任务（比如分类任务）。什么是学习？寻找更好数据表示的自动搜索过程 。
P10 假设我们想要开发个算法，输入一个点的坐标 (x, y)，就能够判断这个点是黑色还是白色。这里输入是点的坐标,预期输出是点的颜色，衡量算法效果的方法就是统计正确分类的点所占的百分比。但显然，用图中的原始坐标系统是不太容易给出分类判断的，我们需要的是一种新的数据表示，可以明确区分白点与黑点。可用的方法有很多，这里用的是坐标变换。在这个新的坐标系中，点的坐标可以看作数据的一种新的表示。利用这种新的表示，用一条简单的规则就可以描述黑 / 白分类问题：“x>0 的是黑点”或“x<0 的是白点”。这种新的表示基本上解决了该分类问题。在这个例子中，我们人为定义了坐标变换。但是，如果我们尝试系统性地搜索各种可能的坐标变换，并用正确分类的点所占百分比作为反馈信号，那么我们做的就是机器学习。 所有机器学习算法都包括自动寻找这样一种变换：这种变换可以根据任务将数据转化为更加有用的表示。这些操作可能是前面提到的坐标变换，也可能是线性投影、平移、非线性操作，等等。
知识点3：深度学习与神经网络概述
P11 深度学习是机器学习的一个分支领域：它是从数据中学习“表示”的一种新方法，强调从连续的层中进行学习，这些层对应于越来越有意义的表示。“深度学习”中的“深度”指的并不是利用这种方法所获取的更深层次的理解，而是指一系列连续的表示层。数据模型中包含多少层，这被称为模型的深度。这一领域的其他名称包括分层表示学习和层级表示学习。
现代深度学习通常包含数十个甚至上百个连续的表示层，这些表示层全都是从训练数据中自动学习的。与此相反，其他机器学习方法的重点往往是仅仅学习一两层的数据表示，因此有时也被称为浅层学习。 
P12 1943年，心理学家沃伦·麦卡洛克(Warren McCulloch)和数学家沃尔特·皮茨（Walter Pitts)根据生物神经元(Neuron)结构，提出了最早的神经元数学模型。该模型的输出，其中,模型通过值完成输出之的预测，如图所示，当，输出为1，当，输出为0，可以看出，MP神经元模型没有学习能力，智能完成固定逻辑的判定。
P13 1958年，美国心理学家弗兰克·罗森布莱特提出了第一个可以自动学习权重的神经元模型，称为感知机，输出值与真实值之间的误差用于调整神经元的权重参数{,,…,}。这种利用误差反馈修正权重的做法，被称之为“学习”。
P14美国心理学家弗兰克·罗森布莱特随后基于“Mark1感知机”硬件实现感知机模型，输入为400个单元的图像传感器，输出为 8个节点端子，可以成功识别一些英文字母。
P15 60年后，深度学习已经成为人工智能领域的主流技术，2018年，ACM决定将当年的图灵奖授予约书亚·本吉奥、杰弗里·辛顿和杨乐昆三位深度学习之父，以表彰他们给人工智能带来的重大突破，这些突破使深度神经网络成为计算的关键组成部分。本吉奥是蒙特利尔大学教授。辛顿是谷歌副总裁兼工程研究员、多伦多大学名誉教授。杨乐昆是纽约大学教授。
P16 2006 年，杰弗里·辛顿首次提出深度学习的概念。 2012 年，8层的深层神经网络AlexNet 发布，并在图片识别竞赛中取得了巨大的性能提升，此后数十层、 数百层、 甚至上千层的神经网络模型相继提出，展现出深层神经网络强大的学习能力。我们一般将利用深层神经网络实现的算法称作深度学习。 
P17 Yann LeCun曾在多伦多大学跟随深度学习鼻祖 Geoffrey Hinton 进行博士后研究。在 20 世纪 80 年代末，Yann LeCun 作为贝尔实验室的研究员提出了卷积网络技术，并展示如何使用它来大幅度提高手写识别能力，目前卷积神经网络已成为计算机视觉、语音识别等众多人工智能应用底层的基石。上世纪末本世纪初，当神经网络失宠时，Yann LeCun 是少数几名一直坚持的科学家之一。他在2021年8月出版的《科学之路：人，机器与未来》书中提到如果你真的相信一个概念，认为一个想法很有价值，就应该努力追求它，尽管可能要等到看到成绩后，人们才会支持这个想法。所以，很多想法真的是在技术成熟之前就诞生的。这里也希望同学你如果针对某些科学或者技术问题进行研究，如果你通过大量的调研认为方向正确，就应该像Yann LeCun 一样坚持自己的观点。
P18 下面我们来看看基于神经网络的深度学习模型是如何体现“深度”和“学习”的。前面提到过，深度学习中的分层是通过神经网络（Neural Network）的模型来学习得到的，其结构是逐层堆叠。虽然深度学习的一些核心概念是从人们对大脑的理解中汲取部分灵感而形成的，但深度学习模型不是大脑模型。没有证据表明大脑的学习机制与现代深度学习模型是完全一致的，因为深度学习模型没有涉及到大脑活动中的生物学与化学等因素。深度学习是从数据中学习表示的一种数学框架。
P19总结一下前面的分析可以得出深度学习的技术定义是学习数据表示的多级方法。这个想法很简单，但事实证明，非常简单的机制如果具有足够大的规模，将会产生魔法般的效果。随着计算能力的提升和大数据时代的到来，高度并行化的 GPU 和海量数据让大规模神经网络的训练成为可能 。深度神经网络将数字图像转换成与原始图像差别越来越大的表示，而其中关于最终结果的信息却越来越丰富。你可以将深度网络看作多级信息蒸馏操作：信息穿过连续的过滤器，其纯度越来越高，得到的信息表示的形式对任务的帮助越来越大。
知识点4：深度学习的工作原理
P20 我想同学一定对深度学习的原理产生了好奇，它是如何从历史数据中学习规则的呢？请先看右边这张示意图，它展示了神经网络的基本结构以及数据的流转过程。首先希望同学理解的是，神经网络中每层对输入数据所做的具体操作保存在该层的权重中，其本质是一串数字。\\\每层实现的变换由其权重来参数化。\\\学习是为神经网络的所有层找到一组权重值，使网络能够将每个示例输入与其目标正确地一一对应。
P21 那么我们如何检验模型的运行效果呢？还记得前面讲到的用于模型训练的数据集的特点么？除了输入数据外，还需要准备样本对应的标签，\\\可以理解为该样本对应的真实值Y，\\\与样本数据输入模型后得到的预测值Y‘比较。这里我们引入一个概念叫“损失函数”\\\，有些文献中也称之为目标函数，它的作用就是衡量模型预测值与真实值之间的误差。
P22 如何利用损失函数得到的误差值进行权重参数优化呢？我们将优化过程的处理具化为一个优化器\\\，这个优化器的目标是根据损失函数的误差值反馈来更新权重参数，由于这个过程在神经网络中是从输出值反向逐层传导到的输入层，所以称之为反向传播算法\\\，这是深度学习的核心算法。一开始对神经网络的权重随机赋值，因此网络只是实现了一系列随机变换。其输出结果自然也和理想值相去甚远，相应地，损失值也很高。但随着网络处理的示例越来越多，权重值也在向正确的方向逐步微调，损失值也逐渐降低。这就是训练循环\\\，将这种循环重复足够多的次数，得到的权重值可以使损失函数最小。那么具有最小损失的网络，其输出值与目标值尽可能地接近，这就是训练好的网络。虽然看似这是一个简单的机制，一旦具有足够大的规模，将会产生神奇的效果。 
P23通过上面的学习，想必大家对人工智能领域的概念已经有了初步的认识，我们来做一个概括。通常，人工智能一般是指一个领域\\\，其中机器学习是人工智能领域中的一种技术流派\\\，而神经网络又是机器学习方法中的一种特定基于神经元数学模型的技术方法\\\，深度学习则是由多层神经元构成的神经网络模型。
本讲就到这里，谢谢。
知识点5：人工智能发展与应用
P24 人工智能已经成为各国重点支持发展的技术领域。到2035年，AI为英国经济额外增加8140亿美元收入；俄罗斯总统普京认为：AI的主导者，也是未来世界规则的制定者；被誉为美国著名的钢铁侠的埃隆马斯克谈及AI，说“国家间对人工智能优势的争夺，很可能引发第三次世界大战。”；人工智能在一定程度在某些领域将会替代人类工作，金融数据服务商高盛肯硕认为“AI会让50％的华尔街分析师失业”，著名投资人李开复也说“未来十年80%的金融从业者会被人工智能取代”。我国也从2016年开始，从规划和产业政策方面对人工智能领域的技术发展进行支撑及引导。2016年3月：“十三五”规划纲要中写入“人工智能”；2016年5月：四部委联合发布“互联网+”人工智能3年行动实施方案；2017年3月：全国两会第一次正式出现“人工智能” ；2017年7月：国务院要求到2030年中国人工智能产业竞争力达到国际。
P25 但实际上人工智能发展不是一帆风顺的，从1956年到2016年60年间，人工智能的发展经历了三起两伏。达特茅斯会议之后的数年是大发现的时代。对许多人而言，这一阶段开发出的各种算法堪称神奇：计算机可以解决代数应用题，证明几何定理，学习和使用英语。但是好景不长，人工智能的第一个寒冬很快到来。70年代初，人工智能开始遭遇批评，即使是最杰出的人工智能程序也只能解决它们尝试解决的问题中最简单的一部分。人工智能研究者们遭遇了无法克服的基础性障碍。随之而来的还有资金上的困难，人工智能研究者们对其课题的难度未能作出正确判断：此前的过于乐观使人们期望过高，当承诺无法兑现时，对人工智能的资助就缩减或取消了。当人类进入到80年代时，一类名为“专家系统”的人工智能程序开始为全世界的公司所采纳，专家系统能够依据一组从专门知识中推演出的逻辑规则在某一特定领域回答或解决问题。而历史总是惊人的相似，人工智能再次遭遇寒冬。最早征兆是1987年硬件市场需求的突然下，Apple和IBM生产的台式机性能不断提升，到1987年时其性能已经超过了一些传统常见生产的昂贵的专用机器，老产品失去了存在的理由。一个普遍认同的说法是，2012年的ImageNet年度挑战开启了这一轮人工智能复兴浪潮，ImageNet是为视觉认知软件研究而设计建立的大型视觉数据库，由华裔人工智能科学家李飞飞2007年发起，ImageNet把深度学习和大数据推到前台，也使大量投资资金涌入。随朕深度学习技术的发展、互联网大数据的积累以及计算性能的大幅提升，许多人工智能的能力已经超越人类，比如围棋、德州扑克，比如证明数学定理，比如学习从海量数据中自动构建知识，识别语音、面孔、指纹，驾驶汽车，处理海量的文件、物流和制造业的自动化操作。能的应用也因此遍地开花，进入人类生活的各个领域。
P26 根据应用范围的不同，人工智能可以分为专用人工智能、通用人工智能、超级人工智能三类，同时，这三个类别也代表着人工智能的不同的发展层次。专用人工智能指如当前的计算机视觉、语音识别等，以一个或多个专门的领域和功能为主，目前正处于高速发展阶段，已取得较为丰富的成果。通用人工智能即机器与人类一样拥有进行所有工作的可能，关键在于自动地认知和拓展。目前正在研究人为地设计尽可能多的功能，通用人工智能目前研究水平仍远远未达到。超级人工智能是指具有自我意识，包括独立自主的价值观、世界观等，与技术的发展不同，超级人工智能的基础是人类对生命科学的全面深入的理解，目前仅存在于文化作品中。我们仍处于专用人工智能阶段。
P27 有四大因素造就AI在近年来的爆发式增长。第一是数据。因为人工智能的根基是训练，就如同人类如果要获取一定的技能，那必须经过不断地训练才能获得，而且有熟能生巧之说。AI也是如此，只有经过大量的训练，神经网络才能总结出规律，应用到新的样本上。对于AI而言，大量的数据太重要了，而且需要覆盖各种可能的场景，这样才能得到一个表现良好的模型，看起来更智能。第二是算力。深度神经网络是非常庞大的系统，要训练出来除了需要很多数据，还需要很强算力的支撑。人工智能算法模型对于算力的巨大需求，也推动了今天芯片业的发展。例如现在训练深度神经网络用到的GPU，更早是用于动画、渲染。深度神经网络的巨大需求，造就了庞大的以GPU为代表的硬件市场。第三是算法。可以说实现人工智能的核心方法是算法，算法是实现人工智能的根本途径，是挖掘数据智能的有效方法。第四点是政策。我国人工智能行业仍处于发展初期，还存在着部分领域产品空白，产品和服务同质化竞争严重，缺乏统一评价标准，技术人才缺乏等问题，需要利用政策手段加以协调，我国人工智能行业政策出台要较美国稍晚，但是很快就从国家层面上将其发展上升到了战略高度。从而可以看出政府把人工智能上升到国家意志的决心，人工智能已成为引领科技发展的重要驱动力。国家政策是我国人工智能行业发展的主要推动力。
P28 2015年7月，国务院出台《关于积极推进“互联网+”行动的指导意见》，首次将人工智能纳入重点任务之一，推动中国人工智能步入新阶段。2017年7月，国务院发布《新一代人工智能发展规划》，战略确立了新一代人工智能发展三步走战略目标，将人工智能上升到国家战略层面。《2019年政府工作报告》首提“新基建”，人工智能作为“新基建”七大领域之一受到广泛关注。2020年8月5日，为加强人工智能领域标准化顶层设计，推动人工智能产业技术研发和标准制定，促进产业健康可持续发展，国家标准委等五部门印发了《国家新一代人工智能标准体系建设指南》。
P29深度学习算法已经广泛应用到人们生活的角角落落，例如手机中的语音助手、 汽车上的智能辅助驾驶、 人脸支付等。我们将为大家介绍深度学习的一些主流应用。图片识别是常见的分类问题。神经网络的输入为图片数据，输出值为当前样本属于每个类别的概率分布。通常选取概率值最大的类别作为样本的预测类别。 图片识别是最早成功应用深度学习的任务之一。目标检测是指通过算法自动检测出图片中常见物体的大致位置，通常用边界框表示，并分类出边界框中物体的类别信息。语义分割是通过算法自动分割并识别出图片中的内容， 可以将语义分割理解为每个像素点的分类问题，分析每个像素点的物体的类别信息。人工智能在机器人控制方面取得了一定的进展。著名美国波士顿动力公司在机器人应用中取得喜人的成就，其制造的机器人在复杂地形行走、 多智能体协作等任务上表现良好。自动驾驶被认为是人工智能强化学习短期内能技术落地的一个应用方向， 很多公司投入大量资源在自动驾驶上，如百度、 Uber、 Google 无人车等，其中百度的无人巴士“阿波龙”已经在北京、雄安、武汉等地展开试运营。
本讲就到这里，谢谢。