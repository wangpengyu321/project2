文件：6.6神经网络搭建流程——优化模型配置
P1、2：同学们大家好，本节课，我们针对神经网络搭建的流程，继续学习优化模型配置这一部分内容。
P3：通过上节课的学习，我们知道，网络模型的最佳训练效果，就是找到模型的最优值，这就涉及到优化模型配置的相关内容。那么优化模型配置主要都有哪些方法呢？我们来看一下，首先，///就是尝试不同的超参数。所谓的超参数，就是关于模型的更高层次的一个概念，其并不能直接从参与网络模型学习训练中的数据中进行学习，而是需要预先定义的。比如说，我们神经网络的层数、每层的单元节点的个数以及优化器的学习率等，都是超参数。因而，这里所说的尝试不同的超参数，主要就是包括///增加或减少层数，或者是///修改每层的单元节点个数或优化器的学习率。可以看出，我们在上一节所学习的增加隐藏层单元节点个数而扩大网络规模的内容，就属于这里面尝试不同超参数的一种模型优化的方法。通过对这些超参数的不同的设置，网络所达到的最优值的情况都会不一样，所以，我们就可以通过尝试不同的超参数，来优化模型的配置。///然后，就是添加dropout，///以及添加 L1 或 L2 正则化的方法，这些方法我们在之前的课程内容中也都讲过。另外，///反复地做特征工程也是一个常用的优化模型配置的方法，也就是通过添加新特征或者是删除没有信息量的特征的相关特征优化方法，来实现优化模型的训练的效果。
P4：好了，通过以上的优化，我们找到了最优的模型参数，并使用训练数据和验证数据训练并得到最优的网络模型后，就需要在测试集上再评估一次。为什么要在测试机上再评估一次呢，之前不是已经最优了吗？这里就需要注意，所谓的最优，都只是在一定的方法和一定的范围内是最优的，也就是所训练好的模型在训练集和验证集中实验了最优，但一旦跨出这些数据的范围，还是不是最优的呢？所以我们需要用模型从未见过的测试集再来测试一下。///假如模型在测试集上的性能比在验证集上差很多，这就可能意味着你的验证流程有问题，你的方法存在问题，或者你在调节模型参数时在验证数据上出现了过拟合。这种情况下，你可能就需要更换更为可靠的评估方法，比如换一种方法，使用重复的K折验证方法来进行评估。这就是我们神经网络优化过程中所涉及到的多次的循环式的调整和优化。也就是，神经网络模型的训练，是要通过不同参数、不同方法，不同数据集，经过很多次的调整和优化，进而来寻找到我们性能最优的网络模型的。
好了，同学们，关于神经网络搭建流程这部分的内容，我们到这里就介绍完了，下节课，我们将通过一个神经网络实战案例，来给大家进一步地介绍神经网络的实现过程。今天的课就介绍到这里，谢谢大家。