P2 在前面的内容中，我们讨论了机器学习是从数据中发现规则的方法。而将这些规则在场景中应用是我们的最终目标。机器学习的目的就是得到可以泛化的模型，即在前所未见的数据上表现很好的模型。而机器学习的核心难点是重复和过多的基于有限数据集进行训练，容易陷入过拟合的困境。\\\例如大家都有学习备考的经验，通常为备考做了一定的习题练习，练习的目的是训练自己的解题思路与技巧，以便在从未见过题目的考试中取得好成绩。但重复做有限的几套题目，存在题目的覆盖面太少的问题。
P3 如何评估模型并通过评估结果改善过拟合现象，成为机器学习一项重要工作。评估模型的重点就是将数据划分为三个集合：训练集、验证集和测试集。在前面的内容中，我们介绍了相关数据集通常被划分为训练集和测试集，即训练集用于模型训练，测试集用于模型测评，这里验证集的功能是什么呢？
P4这里我们还是借用考试的例子给大家类比介绍这三类数据集的功能。首先，使用训练集用来训练模型权重，就像我们每次考前要做大量的“复习题”，\\\然后，我们用验证集对模型的配置进行调节，对应于在正式考试前的“摸底考试”，\\\最后，我们使用测试集检验最终模型的性能，等同于我们参加“正式考试”。这里大家可能有疑问，什么是模型权重？什么是模型配置？
P5模型参数，也称为权重，表示神经元之间的连接关系，使用训练集完成优化和更新；\\\模型配置，也称为超参数，是指神经网络的层数和每层神经网络的神经元个数以及正则化参数。使用验证集完成优化和更新。机器学习的学习，特指在某个参数空间中寻找良好的模型配置。
P6在图中的神经网络中，神经元结点之间的连接为\\\权重，神经网络的层与每层的结点数称之为\\\超参数。
P7我想可能同学还有疑问？为什么不只要设置训练集和测试集就行了，还是多一个验证集呢？\\\请大家注意，训练集的目标是提升模型的表示能力，重点在优化参数，\\\而测试集是为了检验模型在未知数据上的效果，关注的是模型的泛化能力。优化和泛化实际上一对矛盾，\\\所以，我们需要专门设置一个验证数据集，用于改善模型配置，在训练过程完成参数优化后，提升模型的泛化能力。
P8训练集和验证集必须独立设置还有一个原因，就是信息泄露。信息泄露是指每次基于模型在验证集上的性能来调节模型超参数，会有一些关于验证数据的信息泄露到模型中。多次执行就会很快导致模型在验证集上过拟合。所以，不仅不能将训练集当成验证集混用，验证集在模型不变的情况下，也只能只用一次。\\\类比考试也是如此，摸底考试是不能重复执行多次的，否则失去了评估的意义。
P9有了对训练集、验证集和测试集基本概念和作用的认识，我们来看下一这三个集合的数据特点，首先，这3个数据集在数据的形式和分布上是完全一致，这也是训练、评估、测试三个过程的数据基准一致性的保证，在数量比例的划分上，\\\通常为训练集60%，\\\验证集20%\\\测试集20%。
P10 下面我们介绍三种常见的利用验证机改善模型泛化能力的方法，分别为简单留出验证，K折验证，以及打乱数据的重复K折验证。
P11首先来介绍简单的留出验证，顾名思义，就是在原来的训练数据中，划分出一部分数据，用作验证评估。
P12 我们结合代码来看下加入验证过程的模型训练有什么变化。需要说明的是，为了主要展示训练和评估的主要流程，其中关于模型创建和训练的代码以注释方式体现。首先，加载数据集data，并创建network模型。我们仍以MNIST数据集为例，其中数据集加载完成后，已经划分为60000个样本的训练集和10000个样本的测试集，我们需要对训练集再进行细分。\\\定义num_validation_samples变量存放验证数据集规模为10000，\\\然后将数据集进行随机打乱，这一步非常重要，随机化处理能够保证训练集与验证集在样本分布上的一致性。\\\接着,利用列表切片操作，将数据集data的前10000个样本数据留出做验证集，\\\剩余的50000个数据作为训练集，\\\然后使用训练集数据训练模型参数，\\\完成训练后利用验证集评估模型，评估的结果通常可以定义为准确度或者误差损失等，然后根据评估结果调节模型超参数，重新执行训练、评估，再调整模型超参数，反复执行这个过程，直到评估指标满足要求；\\\最后，在确定的网络结构上，利用所有非测试数据从头开始训练最终模型, 并在测试集上进行最终评估。
P13 简单的留出验证有一个缺点，在某些受限条件下，如果可用的数据很少，那么可能验证集和测试集包含的样本就太少，从而无法在统计学上代表数据。 
P14 此时，我们引入K折验证方法。这里的“折”表示分区划分，K折验证将数据划分为K个分区。对每个分区，在剩余的 K-1 个分区上训练模型，在留出的分区上评估模型。最终分数是 K 个分数的平均值。我们以3折验证为例，将数据集划分为3个分区，每次留出其中一个分区作为验证使用，其它两个分区用作训练，在留出的分区上评估模型，每一折都有一个评估验证分数，最终分数为这三个分数的平均值。实际上每一折都是一个简单留出验证过程，K折验证在一定程度上解决了验证集和测试集包含样本太少的问题。
P15 同样，我们也利用代码来看下K折验证的实现过程，假定我们已经完成了数据集data的加载，此时定义K折验证中要划分分区的值，这里假设K=3并采用每个分区数据等分的方式划分\\\这时，每个数据集分区大小就为num_validation_samples，同样的，将数据集进行随机化打乱\\\然后在一个循环体内完成K折训练和验证过程，每轮训练利用列表切片操作依次按照约定的分区大小选择分区数据，确定好验证分区与训练分区，然后创建一个新的网络模型上先使用训练集训练模型参数，\\\再用验证分区数据验证模型并得到一个分值，每次对模型结构的调优都是根据K个得分的平均值进行\\\根据需要重新执行K折训练、评估、再调节超参数，直到验证得分满足要求；\\\最后，在确定的网络结构上，利用所有非测试数据从头开始训练最终模型, 并在测试集上进行最终评估。从上述过程可以看出，K折验证的计算量明显比简单留出验证要大。
P16K折验证面临可用的数据仍然太少，而你又需要尽可能精确地评估模型，那么还可以选择带有打乱数据的重复 K 折验证。具体做法是多次使用 K 折验证，在每次将数据划分为 K 个分区之前都先将数据打乱。最终分数是每次 K 折验证分数的平均值。注意，这种方法一共要训练和评估 P×K 个模型（P是重复次数），计算代价很大。
P17 在评估模型时我们还需要注意一些问题：第一是数据代表性。你希望训练集和测试集都能够代表当前数据。例如，你想要对数字图像进行分类，而图像样本是按类别排序的，如果你将前 80% 作为训练集，剩余 20% 作为测试集，那么会导致训练集中只包含类别 0~7，而测试集中只包含类别 8~9。这个错误看起来很可笑，却很常见。因此，在将数据划分为训练集和测试集之前，通常应该随机打乱数据。\\\其次，需要关注“时间箭头”。如果想要根据过去预测未来（比如明天的天气、股票走势等），那么在划分数据前你不应该随机打乱数据，因为这么做会造成时间泄露，你的模型将在未来数据上得到有效训练。在这种情况下，你应该始终确保测试集中所有数据的时间都晚于训练集数据。\\\最后还要关注“数据冗余”。如果数据中的某些数据点出现了两次或者多次，这在现实中的数据里十分常见，那么打乱数据并划分成训练集和验证集会导致训练集和验证集之间的数据冗余。从效果上来看，你是在部分训练数据上评估模型，所以一定要确保训练集和验证集之间没有交集。
本讲就到这里，谢谢。
